{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","collapsed_sections":["xB4VE0EHsU3O","HvhiVL9ZtDlw"],"authorship_tag":"ABX9TyMoage/hl5SSix/QW6g1XeE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Preperation"],"metadata":{"id":"PRhUfnLCie8q"}},{"cell_type":"markdown","source":["Clone git"],"metadata":{"id":"N4fVeQjcii5l"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mNoFAKazmjGP","executionInfo":{"status":"ok","timestamp":1744479676903,"user_tz":-480,"elapsed":6171,"user":{"displayName":"Sit Chun Yin","userId":"16986499505322810919"}},"outputId":"ae5479ee-0ee7-4649-db26-b618c0f95e11"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'FYP'...\n","remote: Enumerating objects: 34295, done.\u001b[K\n","remote: Total 34295 (delta 0), reused 0 (delta 0), pack-reused 34295 (from 2)\u001b[K\n","Receiving objects: 100% (34295/34295), 25.45 MiB | 11.84 MiB/s, done.\n","Resolving deltas: 100% (24667/24667), done.\n","/content/FYP\n"]}],"source":["!git clone https://github.com/Sitchunyin/FYP.git\n","%cd FYP"]},{"cell_type":"markdown","source":["Ultralytics download"],"metadata":{"id":"kNU_-nzNiowb"}},{"cell_type":"code","source":["!pip install ultralytics"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pdUmjf1OnAj6","executionInfo":{"status":"ok","timestamp":1744479778375,"user_tz":-480,"elapsed":101469,"user":{"displayName":"Sit Chun Yin","userId":"16986499505322810919"}},"outputId":"8e24452c-8f40-4fd6-9516-2be5937b37e8"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ultralytics\n","  Downloading ultralytics-8.3.107-py3-none-any.whl.metadata (37 kB)\n","Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n","Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.14.1)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n","Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n","  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n","Downloading ultralytics-8.3.107-py3-none-any.whl (974 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m974.5/974.5 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m97.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n","Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.107 ultralytics-thop-2.0.14\n"]}]},{"cell_type":"markdown","source":["Dataset download"],"metadata":{"id":"ycfCLIzVisGH"}},{"cell_type":"code","source":["!pip install roboflow\n","\n","from roboflow import Roboflow\n","rf = Roboflow(api_key=\"wAVJNZGUfIR9dKNzxSqW\")\n","project = rf.workspace(\"fyp-mouse-dataset\").project(\"550-base-custom-thermal\")\n","version = project.version(1)\n","dataset = version.download(\"yolov11\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J5PM6gE6ncdm","executionInfo":{"status":"ok","timestamp":1743476870086,"user_tz":-480,"elapsed":16411,"user":{"displayName":"Sit Chun Yin","userId":"16986499505322810919"}},"outputId":"0f94983f-5f6a-4246-92f7-99820a9c3cf9","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting roboflow\n","  Downloading roboflow-1.1.58-py3-none-any.whl.metadata (9.7 kB)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from roboflow) (2025.1.31)\n","Collecting idna==3.7 (from roboflow)\n","  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n","Requirement already satisfied: cycler in /usr/local/lib/python3.11/dist-packages (from roboflow) (0.12.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.4.8)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from roboflow) (3.10.0)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.0.2)\n","Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n","  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n","Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from roboflow) (11.1.0)\n","Collecting pillow-heif>=0.18.0 (from roboflow)\n","  Downloading pillow_heif-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.8.2)\n","Collecting python-dotenv (from roboflow)\n","  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.32.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.17.0)\n","Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.3.0)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from roboflow) (4.67.1)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (6.0.2)\n","Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.0.0)\n","Collecting filetype (from roboflow)\n","  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (1.3.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (4.56.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (24.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (3.2.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->roboflow) (3.4.1)\n","Downloading roboflow-1.1.58-py3-none-any.whl (84 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pillow_heif-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n","Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n","Installing collected packages: filetype, python-dotenv, pillow-heif, opencv-python-headless, idna, roboflow\n","  Attempting uninstall: opencv-python-headless\n","    Found existing installation: opencv-python-headless 4.11.0.86\n","    Uninstalling opencv-python-headless-4.11.0.86:\n","      Successfully uninstalled opencv-python-headless-4.11.0.86\n","  Attempting uninstall: idna\n","    Found existing installation: idna 3.10\n","    Uninstalling idna-3.10:\n","      Successfully uninstalled idna-3.10\n","Successfully installed filetype-1.2.0 idna-3.7 opencv-python-headless-4.10.0.84 pillow-heif-0.22.0 python-dotenv-1.1.0 roboflow-1.1.58\n","loading Roboflow workspace...\n","loading Roboflow project...\n"]},{"output_type":"stream","name":"stderr","text":["Downloading Dataset Version Zip in 550-base-+-custom-thermal-1 to yolov11:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15859/15859 [00:00<00:00, 31788.07it/s]"]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["\n","Extracting Dataset Version Zip to 550-base-+-custom-thermal-1 in yolov11:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1496/1496 [00:00<00:00, 9940.68it/s]\n"]}]},{"cell_type":"code","source":["!pip install roboflow\n","\n","from roboflow import Roboflow\n","rf = Roboflow(api_key=\"wAVJNZGUfIR9dKNzxSqW\")\n","project = rf.workspace(\"fyp-mouse-dataset\").project(\"3316base-custom-thermal\")\n","version = project.version(3)\n","dataset = version.download(\"yolov11\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0k9QregBkxMd","executionInfo":{"status":"ok","timestamp":1744479802573,"user_tz":-480,"elapsed":24195,"user":{"displayName":"Sit Chun Yin","userId":"16986499505322810919"}},"outputId":"0880a41a-0e1d-416f-8654-c8041abd2ce2"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting roboflow\n","  Downloading roboflow-1.1.61-py3-none-any.whl.metadata (9.7 kB)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from roboflow) (2025.1.31)\n","Collecting idna==3.7 (from roboflow)\n","  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n","Requirement already satisfied: cycler in /usr/local/lib/python3.11/dist-packages (from roboflow) (0.12.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.4.8)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from roboflow) (3.10.0)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.0.2)\n","Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n","  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n","Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from roboflow) (11.1.0)\n","Collecting pillow-heif>=0.18.0 (from roboflow)\n","  Downloading pillow_heif-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.8.2)\n","Collecting python-dotenv (from roboflow)\n","  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.32.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.17.0)\n","Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.3.0)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from roboflow) (4.67.1)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (6.0.2)\n","Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.0.0)\n","Collecting filetype (from roboflow)\n","  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (1.3.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (4.57.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (24.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (3.2.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->roboflow) (3.4.1)\n","Downloading roboflow-1.1.61-py3-none-any.whl (85 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m85.2/85.2 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pillow_heif-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n","Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n","Installing collected packages: filetype, python-dotenv, pillow-heif, opencv-python-headless, idna, roboflow\n","  Attempting uninstall: opencv-python-headless\n","    Found existing installation: opencv-python-headless 4.11.0.86\n","    Uninstalling opencv-python-headless-4.11.0.86:\n","      Successfully uninstalled opencv-python-headless-4.11.0.86\n","  Attempting uninstall: idna\n","    Found existing installation: idna 3.10\n","    Uninstalling idna-3.10:\n","      Successfully uninstalled idna-3.10\n","Successfully installed filetype-1.2.0 idna-3.7 opencv-python-headless-4.10.0.84 pillow-heif-0.22.0 python-dotenv-1.1.0 roboflow-1.1.61\n","loading Roboflow workspace...\n","loading Roboflow project...\n"]},{"output_type":"stream","name":"stderr","text":["Downloading Dataset Version Zip in 3316base+-custom-thermal-3 to yolov11:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61790/61790 [00:04<00:00, 12734.49it/s]"]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["\n","Extracting Dataset Version Zip to 3316base+-custom-thermal-3 in yolov11:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7026/7026 [00:00<00:00, 8866.83it/s]\n"]}]},{"cell_type":"markdown","source":["# ***Code for LDConv***"],"metadata":{"id":"xB4VE0EHsU3O"}},{"cell_type":"code","source":["from ultralytics import YOLO\n","import warnings\n","warnings.filterwarnings('ignore')\n","from pathlib import Path\n","\n","if __name__ == '__main__':\n","    # Load the pre-trained YOLO model\n","    model = YOLO('/content/FYP/yolo11n.pt')  # Load the original YOLO weights\n","\n","    # Modify the model configuration to include your custom backbone\n","    custom_model = YOLO('/content/FYP/ultralytics/cfg/models/11/yolo11_LDConv.yaml')\n","    model.model = custom_model.model\n","\n","    # Fine-tune the model on your custom dataset\n","    results = model.train(data='/content/FYP/3316base+-custom-thermal-3/data.yaml',  # Update with your dataset path\n","                          epochs=40, batch=16, imgsz=640, workers=4, name='custom_yolo11n')  # Train the model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7HUihwnhoBtn","outputId":"e8345031-98c3-4e51-a159-6573825ceb7e","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING âš ï¸ no model scale passed. Assuming scale='n'.\n","New https://pypi.org/project/ultralytics/8.3.107 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n","Ultralytics 8.3.78 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/content/FYP/yolo11n.pt, data=/content/FYP/3316base+-custom-thermal-3/data.yaml, epochs=40, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=4, project=None, name=custom_yolo11n2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/FYP/runs/detect/custom_yolo11n2\n","Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 119MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Overriding model.yaml nc=80 with nc=2\n","WARNING âš ï¸ no model scale passed. Assuming scale='n'.\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       344  ultralytics.nn.modules.LDConv.LDConv         [3, 16, 3, 2]                 \n","  1                  -1  1      2470  ultralytics.nn.modules.LDConv.LDConv         [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     15878  ultralytics.nn.modules.LDConv.LDConv         [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1     56326  ultralytics.nn.modules.LDConv.LDConv         [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    105734  ultralytics.nn.modules.LDConv.LDConv         [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n"," 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n"," 17                  -1  1     15878  ultralytics.nn.modules.LDConv.LDConv         [64, 64, 3, 2]                \n"," 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n"," 20                  -1  1     56326  ultralytics.nn.modules.LDConv.LDConv         [128, 128, 3, 2]              \n"," 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n"," 23        [16, 19, 22]  1    431062  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n","YOLO11_LDConv summary: 195 layers, 2,173,218 parameters, 2,173,202 gradients\n","\n","Transferred 462/513 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/FYP/runs/detect/custom_yolo11n2', view at http://localhost:6006/\n","Freezing layer 'model.23.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/FYP/3316base+-custom-thermal-3/train/labels... 2454 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2454/2454 [00:01<00:00, 2331.88it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/FYP/3316base+-custom-thermal-3/train/labels.cache\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/FYP/3316base+-custom-thermal-3/valid/labels... 702 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 702/702 [00:00<00:00, 879.15it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/FYP/3316base+-custom-thermal-3/valid/labels.cache\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to /content/FYP/runs/detect/custom_yolo11n2/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 81 weight(decay=0.0), 95 weight(decay=0.0005), 94 bias(decay=0.0)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mWARNING âš ï¸ TensorBoard graph visualization failure Modules that have backward hooks assigned can't be compiled: Conv2d(3, 6, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/content/FYP/runs/detect/custom_yolo11n2\u001b[0m\n","Starting training for 40 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       1/40      7.01G      3.354      4.433      3.702         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [03:27<00:00,  1.35s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:10<00:00,  2.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all        702       1037      0.661      0.116     0.0913     0.0274\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       2/40         7G      2.511      2.665      2.681          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [03:23<00:00,  1.32s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:09<00:00,  2.32it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        702       1037      0.745      0.255      0.206     0.0713\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       3/40         7G      2.219      2.151      2.379         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [03:23<00:00,  1.32s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:09<00:00,  2.38it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        702       1037      0.785      0.256      0.237     0.0935\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       4/40         7G       2.06      1.866      2.215         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [03:23<00:00,  1.32s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:09<00:00,  2.39it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        702       1037      0.787      0.286      0.322      0.119\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       5/40      7.01G      1.926      1.731      2.095         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [03:23<00:00,  1.32s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:08<00:00,  2.50it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        702       1037       0.83      0.278      0.337      0.161\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       6/40      6.99G      1.799      1.601      1.997         23        640:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 125/154 [02:46<00:38,  1.33s/it]"]}]},{"cell_type":"markdown","source":["# ***Code for GSConv***"],"metadata":{"id":"HvhiVL9ZtDlw"}},{"cell_type":"code","source":["from ultralytics import YOLO\n","import warnings\n","warnings.filterwarnings('ignore')\n","from pathlib import Path\n","\n","if __name__ == '__main__':\n","    # Load the pre-trained YOLO model\n","    model = YOLO('/content/FYP/yolo11n.pt')  # Load the original YOLO weights\n","\n","    # Modify the model configuration to include your custom backbone\n","    custom_model = YOLO('/content/FYP/ultralytics/cfg/models/11/yolo11_GSConv.yaml')\n","    model.model = custom_model.model\n","\n","    # Fine-tune the model on your custom dataset\n","    results = model.train(data='/content/FYP/3316base+-custom-thermal-1/data.yaml',  # Update with your dataset path\n","                          epochs=40, batch=16, imgsz=640, workers=4, name='custom_yolo11n')  # Train the model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R-8wbAbYtCWW","executionInfo":{"status":"ok","timestamp":1743346893740,"user_tz":-480,"elapsed":2120173,"user":{"displayName":"Sit Chun Yin","userId":"16986499505322810919"}},"outputId":"26152748-70ff-4765-da34-e691314d7976"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Creating new Ultralytics Settings v0.0.6 file âœ… \n","View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n","Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n","WARNING âš ï¸ no model scale passed. Assuming scale='n'.\n","New https://pypi.org/project/ultralytics/8.3.99 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n","Ultralytics 8.3.78 ğŸš€ Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/content/FYP/yolo11n.pt, data=/content/FYP/3316base+-custom-thermal-1/data.yaml, epochs=40, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=4, project=None, name=custom_yolo11n, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/FYP/runs/detect/custom_yolo11n\n","Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 104MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Overriding model.yaml nc=80 with nc=3\n","WARNING âš ï¸ no model scale passed. Assuming scale='n'.\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       448  ultralytics.nn.modules.conv.GSConv           [3, 16, 3, 2]                 \n","  1                  -1  1      2768  ultralytics.nn.modules.conv.GSConv           [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     19360  ultralytics.nn.modules.conv.GSConv           [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1     75584  ultralytics.nn.modules.conv.GSConv           [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    151168  ultralytics.nn.modules.conv.GSConv           [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n"," 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n"," 17                  -1  1     19360  ultralytics.nn.modules.conv.GSConv           [64, 64, 3, 2]                \n"," 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n"," 20                  -1  1     75584  ultralytics.nn.modules.conv.GSConv           [128, 128, 3, 2]              \n"," 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n"," 23        [16, 19, 22]  1    431257  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n","YOLO11_GSConv summary: 195 layers, 2,264,729 parameters, 2,264,713 gradients, 5.7 GFLOPs\n","\n","Transferred 490/541 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/FYP/runs/detect/custom_yolo11n', view at http://localhost:6006/\n","Freezing layer 'model.23.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/FYP/3316base+-custom-thermal-1/train/labels... 2454 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2454/2454 [00:01<00:00, 2415.49it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/FYP/3316base+-custom-thermal-1/train/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/FYP/3316base+-custom-thermal-1/valid/labels... 702 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 702/702 [00:00<00:00, 854.54it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/FYP/3316base+-custom-thermal-1/valid/labels.cache\n","Plotting labels to /content/FYP/runs/detect/custom_yolo11n/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 88 weight(decay=0.0), 95 weight(decay=0.0005), 94 bias(decay=0.0)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/content/FYP/runs/detect/custom_yolo11n\u001b[0m\n","Starting training for 40 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       1/40      2.43G      3.403      4.592      3.632         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:50<00:00,  3.04it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:06<00:00,  3.25it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        702       1037      0.716     0.0825       0.03    0.00731\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       2/40      2.29G      2.413       2.68      2.547          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:46<00:00,  3.31it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:06<00:00,  3.41it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        702       1037       0.48      0.158      0.134     0.0451\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       3/40      2.29G      2.093      2.082      2.218         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:45<00:00,  3.37it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:06<00:00,  3.36it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        702       1037      0.887       0.19      0.287      0.113\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       4/40      2.29G       1.89      1.772       2.03         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:45<00:00,  3.41it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:06<00:00,  3.41it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        702       1037      0.718      0.311      0.345      0.136\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       5/40       2.3G      1.762      1.596      1.899         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:45<00:00,  3.42it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:06<00:00,  3.39it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        702       1037      0.434      0.381      0.407      0.184\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       6/40      2.29G      1.666      1.451      1.841         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:45<00:00,  3.42it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:06<00:00,  3.38it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        702       1037      0.656      0.515      0.557      0.259\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       7/40       2.3G      1.586      1.336      1.757         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:44<00:00,  3.46it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:06<00:00,  3.45it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        702       1037      0.538      0.513      0.519      0.233\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       8/40      2.31G      1.534       1.25       1.71         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:44<00:00,  3.46it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:06<00:00,  3.43it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        702       1037      0.606      0.588      0.602      0.285\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       9/40      2.29G      1.509      1.216      1.685         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:44<00:00,  3.44it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:06<00:00,  3.49it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        702       1037      0.623      0.553      0.646      0.314\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      10/40      2.31G      1.443      1.133       1.63          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:44<00:00,  3.44it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:06<00:00,  3.56it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        702       1037       0.58      0.575      0.552       0.29\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      11/40       2.3G      1.419      1.084      1.618         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:43<00:00,  3.54it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:06<00:00,  3.39it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        702       1037      0.607      0.572      0.609      0.316\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      12/40      2.29G      1.378      1.027      1.551         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:44<00:00,  3.47it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:06<00:00,  3.40it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        702       1037      0.781       0.58      0.643      0.357\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      13/40       2.3G      1.351      1.002      1.549          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:44<00:00,  3.47it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:06<00:00,  3.51it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        702       1037      0.678      0.705      0.748       0.41\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      14/40      2.29G       1.34     0.9839       1.54         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:44<00:00,  3.44it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  3.70it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        702       1037      0.669      0.709      0.758      0.399\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      15/40       2.3G      1.301     0.9341      1.498         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:44<00:00,  3.49it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:06<00:00,  3.58it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        702       1037      0.654      0.684      0.701      0.403\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      16/40       2.3G      1.301     0.9357      1.519          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:43<00:00,  3.51it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:06<00:00,  3.46it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        702       1037      0.627      0.752      0.762      0.435\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      17/40      2.29G       1.27      0.896      1.485         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:44<00:00,  3.46it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:06<00:00,  3.51it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        702       1037      0.559      0.667      0.703      0.428\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      18/40      2.29G      1.251     0.9102      1.473         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:45<00:00,  3.39it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:06<00:00,  3.55it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        702       1037      0.712      0.769      0.811      0.482\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      19/40      2.29G       1.25     0.8611      1.463         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:45<00:00,  3.39it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  3.77it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        702       1037      0.774      0.619       0.68      0.395\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      20/40      2.29G      1.219     0.8343       1.43         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:45<00:00,  3.39it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  3.86it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        702       1037      0.652      0.716      0.704      0.409\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      21/40      2.29G      1.223     0.8252      1.438         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:44<00:00,  3.44it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  3.80it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        702       1037      0.654      0.742      0.752       0.45\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      22/40      2.29G      1.207     0.8154      1.422         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:44<00:00,  3.44it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  3.74it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        702       1037      0.734      0.793      0.798      0.484\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      23/40       2.3G      1.195     0.8201      1.414         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:44<00:00,  3.45it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:06<00:00,  3.66it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        702       1037      0.732      0.742      0.759      0.472\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      24/40      2.29G      1.195     0.7955      1.416         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:45<00:00,  3.38it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  3.89it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        702       1037      0.818      0.779      0.849      0.514\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      25/40       2.3G      1.156     0.7634      1.382         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:45<00:00,  3.39it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  3.93it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        702       1037      0.817      0.728      0.824        0.5\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      26/40      2.33G      1.147     0.7661      1.376          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:45<00:00,  3.35it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  4.13it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        702       1037      0.768      0.774       0.82      0.519\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      27/40      2.29G      1.149     0.7724      1.385         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:45<00:00,  3.37it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  4.00it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        702       1037      0.819      0.775      0.851      0.535\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      28/40      2.29G      1.159     0.7532      1.384         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:46<00:00,  3.34it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  4.07it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        702       1037      0.741      0.825      0.814      0.527\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      29/40       2.3G      1.138     0.7357       1.37         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:45<00:00,  3.40it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  4.00it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        702       1037      0.785      0.775      0.842      0.553\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      30/40      2.33G      1.113     0.7169      1.341         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:45<00:00,  3.36it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  4.00it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        702       1037      0.836      0.758      0.838      0.519\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      31/40      2.48G      1.033     0.6696      1.343          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:45<00:00,  3.40it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  4.12it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        702       1037      0.775      0.835       0.85      0.538\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      32/40      2.29G      1.026     0.6263      1.337         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:44<00:00,  3.49it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  4.10it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        702       1037      0.831      0.714      0.838       0.54\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      33/40      2.29G      1.004     0.6189      1.316         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:44<00:00,  3.45it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  4.13it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        702       1037      0.768      0.841      0.845      0.557\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      34/40      2.29G      0.985     0.5912      1.301          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:44<00:00,  3.43it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  4.07it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        702       1037      0.753        0.9      0.847      0.562\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      35/40      2.29G     0.9887     0.6014        1.3          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:43<00:00,  3.53it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:06<00:00,  3.60it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        702       1037      0.755      0.836      0.819      0.528\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      36/40      2.29G     0.9868     0.5881      1.294         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:43<00:00,  3.53it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:06<00:00,  3.46it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        702       1037      0.737      0.903      0.831      0.543\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      37/40      2.29G     0.9577     0.5774      1.274          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:43<00:00,  3.57it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:06<00:00,  3.39it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        702       1037      0.839      0.844      0.886      0.589\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      38/40      2.29G     0.9524     0.5643      1.271         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:43<00:00,  3.54it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:06<00:00,  3.49it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        702       1037      0.775      0.892      0.864      0.581\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      39/40      2.29G     0.9474     0.5608       1.27          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:42<00:00,  3.58it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:06<00:00,  3.46it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        702       1037      0.834      0.861      0.871      0.579\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      40/40      2.29G     0.9407      0.558       1.27         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:43<00:00,  3.57it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  3.80it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        702       1037      0.833      0.854      0.881      0.585\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","40 epochs completed in 0.577 hours.\n","Optimizer stripped from /content/FYP/runs/detect/custom_yolo11n/weights/last.pt, 4.8MB\n","Optimizer stripped from /content/FYP/runs/detect/custom_yolo11n/weights/best.pt, 4.8MB\n","\n","Validating /content/FYP/runs/detect/custom_yolo11n/weights/best.pt...\n","Ultralytics 8.3.78 ğŸš€ Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLO11_GSConv summary (fused): 107 layers, 2,257,041 parameters, 0 gradients, 5.5 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:07<00:00,  2.93it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all        702       1037       0.84      0.843      0.886      0.589\n","                 Mouse        661        958      0.964      0.965       0.99      0.763\n","                Person         36         39      0.678      0.846      0.843      0.555\n","                 mouse         39         40      0.878      0.719      0.826      0.449\n","Speed: 0.2ms preprocess, 3.0ms inference, 0.0ms loss, 1.7ms postprocess per image\n","Results saved to \u001b[1m/content/FYP/runs/detect/custom_yolo11n\u001b[0m\n"]}]},{"cell_type":"markdown","source":["# Custom edition"],"metadata":{"id":"pbkQE7AeA8mJ"}},{"cell_type":"code","source":["from ultralytics import YOLO\n","import warnings\n","warnings.filterwarnings('ignore')\n","from pathlib import Path\n","import torch\n","\n","if __name__ == '__main__':\n","    # Load the pre-trained YOLO model\n","    model = YOLO('/content/FYP/yolo11n.pt')  # Load the original YOLO weights\n","\n","    # Modify the model configuration to include your custom backbone\n","    custom_model = YOLO('/content/FYP/ultralytics/cfg/models/11/yolo11_slimneck.yaml')\n","\n","    model.model = custom_model.model\n","\n","    # Clear GPU memory\n","    torch.cuda.empty_cache()\n","\n","    # Fine-tune the model on your custom dataset\n","    results = model.train(data='/content/FYP/3316base+-custom-thermal-3/data.yaml',  # Update with your dataset path\n","                          epochs=40, batch=8, imgsz=416, workers=4, cache=False, name='custom_yolo11n')  # Train the model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"id":"h5Zj93et722H","executionInfo":{"status":"error","timestamp":1744393475909,"user_tz":-480,"elapsed":287,"user":{"displayName":"Sit Chun Yin","userId":"16986499505322810919"}},"outputId":"af55bffe-c235-4502-bedc-1223639aec57"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING âš ï¸ no model scale passed. Assuming scale='n'.\n"]},{"output_type":"error","ename":"ValueError","evalue":"groups must be a positive integer","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-48153ded59fa>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Modify the model configuration to include your custom backbone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mcustom_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/FYP/ultralytics/cfg/models/11/yolo11_slimneck.yaml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/FYP/ultralytics/models/yolo/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, task, verbose)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;31m# Continue with default YOLO initialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/FYP/ultralytics/engine/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, task, verbose)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"os\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUBLAS_WORKSPACE_CONFIG\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\":4096:8\"\u001b[0m  \u001b[0;31m# to avoid deterministic warnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuffix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\".yaml\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".yml\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/FYP/ultralytics/engine/model.py\u001b[0m in \u001b[0;36m_new\u001b[0;34m(self, cfg, task, model, verbose)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mguess_model_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_smart_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# build model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"task\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/FYP/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cfg, ch, nc, verbose)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Overriding model.yaml nc={self.yaml['nc']} with nc={nc}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"nc\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnc\u001b[0m  \u001b[0;31m# override YAML value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# model, savelist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34mf\"{i}\"\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"nc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m  \u001b[0;31m# default names dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inplace\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/FYP/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mparse_model\u001b[0;34m(d, ch, verbose)\u001b[0m\n\u001b[1;32m   1090\u001b[0m             \u001b[0mc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1092\u001b[0;31m         \u001b[0mm_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1093\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__main__.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# module type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m         \u001b[0mm_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mm_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# number params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/FYP/ultralytics/nn/modules/conv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, c1, c2, n, shortcut, g, e)\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgsb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGSBottleneck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mc_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/FYP/ultralytics/nn/modules/conv.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgsb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGSBottleneck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mc_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/FYP/ultralytics/nn/modules/conv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, c1, c2, k, s, e)\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;31m# for lighting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         self.conv_lighting = nn.Sequential(\n\u001b[0;32m--> 399\u001b[0;31m             \u001b[0mGSConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m             GSConv(c_, c2, 3, 1, act=False))\n\u001b[1;32m    401\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshortcut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/FYP/ultralytics/nn/modules/conv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, c1, c2, k, s, p, g, d, act)\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0mc_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc2\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_act\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_act\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/FYP/ultralytics/nn/modules/conv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, c1, c2, k, s, p, g, d, act)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;34m\"\"\"Initialize Conv layer with given arguments including activation.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautopad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNorm2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_act\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mact\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mact\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIdentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, padding_mode, device, dtype)\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0mpadding_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpadding\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0mdilation_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0min_channels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, bias, padding_mode, device, dtype)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"groups must be a positive integer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0min_channels\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"in_channels must be divisible by groups\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: groups must be a positive integer"]}]},{"cell_type":"markdown","source":["# ***Testing***"],"metadata":{"id":"jj33lxMbL5uv"}},{"cell_type":"markdown","source":["model mAP value"],"metadata":{"id":"s8Gof7kThOhd"}},{"cell_type":"code","source":["from ultralytics import YOLO\n","\n","# Load a model\n","model = YOLO(\"/content/FYP/runs/detect/custom_yolo11n/weights/best.pt\") #change to test model path\n","\n","# Validate with a custom dataset\n","\n","metrics = model.val(data=\"/content/FYP/3316base+-custom-thermal-3/data.yaml\") #path of dataset\n","\n","print(metrics.box.map50)  # mAP50\n","print(metrics.box.map75)  # mAP75\n","print(metrics.box.map)  # mAP50-95\n","print(metrics.box.maps)  # list of mAP50-95 for each category"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5fLL5vBhgYIT","executionInfo":{"status":"ok","timestamp":1744387870269,"user_tz":-480,"elapsed":9225,"user":{"displayName":"Sit Chun Yin","userId":"16986499505322810919"}},"outputId":"43ef4113-1e9a-423a-f510-e701bb2edf51"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.78 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","YOLO11 summary (fused): 100 layers, 2,582,542 parameters, 0 gradients, 6.3 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/FYP/3316base+-custom-thermal-3/valid/labels.cache... 702 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 702/702 [00:00<?, ?it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [00:06<00:00,  7.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all        702       1037      0.827      0.821      0.894      0.612\n","                 Mouse        700        998      0.992      0.846      0.987      0.739\n","                Person         36         39      0.662      0.795        0.8      0.486\n","Speed: 0.3ms preprocess, 2.6ms inference, 0.0ms loss, 1.1ms postprocess per image\n","Results saved to \u001b[1m/content/FYP/runs/detect/val\u001b[0m\n","0.893607271828879\n","0.6983290902442337\n","0.6122401168672191\n","[    0.73864     0.48584]\n"]}]},{"cell_type":"markdown","source":["Video test"],"metadata":{"id":"m5dt0M2SixuF"}},{"cell_type":"code","source":["from google.colab import files\n","from ultralytics import YOLO\n","import cv2\n","import time  # Import the time module\n","\n","# Assuming the video file is named 'test_video.mp4'\n","video_path = '/content/rat_sample_video.mp4'\n","\n","# Step 2: Load the trained model and weights\n","model = YOLO(\"/content/FYP/runs/detect/custom_yolo11n/weights/best.pt\")  # Load the best weights directly\n","model.to('cpu')  # Switch to CPU mode for debugging\n","\n","# Step 3: Process the video\n","cap = cv2.VideoCapture(video_path)\n","out = cv2.VideoWriter('output_video.mp4', cv2.VideoWriter_fourcc(*'mp4v'), 20.0, (int(cap.get(3)), int(cap.get(4))))\n","\n","# Start timing\n","start_time = time.time()\n","\n","while cap.isOpened():\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","\n","    # Make predictions\n","    results = model(frame)\n","\n","    # Draw bounding boxes and labels on the frame\n","    for result in results:\n","        for box in result.boxes:\n","            x1, y1, x2, y2 = [int(coord) for coord in box.xyxy.flatten()]\n","            label = int(box.cls)  # Use cls for class labels\n","            confidence = float(box.conf)  # Use conf for confidence scores\n","\n","            # Draw the bounding box\n","            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n","            # Put the label and confidence\n","            cv2.putText(frame, f'{label} {confidence:.2f}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n","\n","    # Write the frame to the output video\n","    out.write(frame)\n","\n","cap.release()\n","out.release()\n","\n","# End timing\n","end_time = time.time()\n","\n","# Calculate the total processing time\n","processing_time = end_time - start_time\n","print(f\"Total processing time: {processing_time:.2f} seconds\")\n","\n","# Download the output video\n","files.download('output_video.mp4')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"vrozYKBaL5BB","executionInfo":{"status":"ok","timestamp":1744388009832,"user_tz":-480,"elapsed":26140,"user":{"displayName":"Sit Chun Yin","userId":"16986499505322810919"}},"outputId":"98513887-28e8-4783-ba5a-c7e700c2bf97"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","0: 256x416 1 Mouse, 62.9ms\n","Speed: 4.7ms preprocess, 62.9ms inference, 52.0ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 57.8ms\n","Speed: 1.7ms preprocess, 57.8ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 49.9ms\n","Speed: 1.5ms preprocess, 49.9ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 50.0ms\n","Speed: 1.5ms preprocess, 50.0ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 45.5ms\n","Speed: 1.5ms preprocess, 45.5ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 50.0ms\n","Speed: 1.5ms preprocess, 50.0ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 44.2ms\n","Speed: 1.5ms preprocess, 44.2ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 47.9ms\n","Speed: 1.4ms preprocess, 47.9ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 47.3ms\n","Speed: 1.5ms preprocess, 47.3ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 46.6ms\n","Speed: 1.5ms preprocess, 46.6ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 44.4ms\n","Speed: 1.5ms preprocess, 44.4ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 45.3ms\n","Speed: 1.4ms preprocess, 45.3ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 47.8ms\n","Speed: 1.5ms preprocess, 47.8ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 44.2ms\n","Speed: 1.5ms preprocess, 44.2ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 45.2ms\n","Speed: 1.6ms preprocess, 45.2ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 47.2ms\n","Speed: 2.3ms preprocess, 47.2ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 48.5ms\n","Speed: 1.7ms preprocess, 48.5ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 49.3ms\n","Speed: 1.7ms preprocess, 49.3ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 56.0ms\n","Speed: 1.6ms preprocess, 56.0ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 45.1ms\n","Speed: 1.6ms preprocess, 45.1ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 45.9ms\n","Speed: 1.6ms preprocess, 45.9ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 44.7ms\n","Speed: 2.0ms preprocess, 44.7ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 45.3ms\n","Speed: 1.9ms preprocess, 45.3ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 47.1ms\n","Speed: 1.7ms preprocess, 47.1ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 46.6ms\n","Speed: 2.1ms preprocess, 46.6ms inference, 0.9ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 50.9ms\n","Speed: 1.9ms preprocess, 50.9ms inference, 0.9ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 46.2ms\n","Speed: 1.8ms preprocess, 46.2ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 46.8ms\n","Speed: 1.7ms preprocess, 46.8ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 45.8ms\n","Speed: 1.7ms preprocess, 45.8ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 49.0ms\n","Speed: 1.6ms preprocess, 49.0ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 47.4ms\n","Speed: 1.8ms preprocess, 47.4ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 46.2ms\n","Speed: 1.6ms preprocess, 46.2ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 46.4ms\n","Speed: 1.6ms preprocess, 46.4ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 47.4ms\n","Speed: 1.6ms preprocess, 47.4ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 46.6ms\n","Speed: 1.6ms preprocess, 46.6ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 56.0ms\n","Speed: 1.6ms preprocess, 56.0ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 45.7ms\n","Speed: 1.5ms preprocess, 45.7ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 46.2ms\n","Speed: 1.2ms preprocess, 46.2ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 45.6ms\n","Speed: 1.5ms preprocess, 45.6ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 47.3ms\n","Speed: 1.7ms preprocess, 47.3ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 46.1ms\n","Speed: 1.6ms preprocess, 46.1ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 45.2ms\n","Speed: 1.6ms preprocess, 45.2ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 46.9ms\n","Speed: 1.5ms preprocess, 46.9ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 47.2ms\n","Speed: 2.1ms preprocess, 47.2ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 46.1ms\n","Speed: 1.6ms preprocess, 46.1ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 47.1ms\n","Speed: 1.5ms preprocess, 47.1ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 45.5ms\n","Speed: 1.5ms preprocess, 45.5ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 45.0ms\n","Speed: 1.5ms preprocess, 45.0ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 49.4ms\n","Speed: 1.6ms preprocess, 49.4ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 46.8ms\n","Speed: 1.5ms preprocess, 46.8ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 44.6ms\n","Speed: 1.5ms preprocess, 44.6ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 45.9ms\n","Speed: 1.6ms preprocess, 45.9ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 58.0ms\n","Speed: 1.6ms preprocess, 58.0ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 45.0ms\n","Speed: 1.4ms preprocess, 45.0ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 45.1ms\n","Speed: 1.5ms preprocess, 45.1ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 48.6ms\n","Speed: 1.5ms preprocess, 48.6ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 47.1ms\n","Speed: 1.6ms preprocess, 47.1ms inference, 0.9ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 49.1ms\n","Speed: 1.6ms preprocess, 49.1ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 48.2ms\n","Speed: 2.1ms preprocess, 48.2ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 46.2ms\n","Speed: 1.8ms preprocess, 46.2ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 46.0ms\n","Speed: 1.7ms preprocess, 46.0ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 49.7ms\n","Speed: 1.8ms preprocess, 49.7ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 48.1ms\n","Speed: 1.8ms preprocess, 48.1ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 45.7ms\n","Speed: 1.8ms preprocess, 45.7ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 45.7ms\n","Speed: 1.7ms preprocess, 45.7ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 47.6ms\n","Speed: 2.0ms preprocess, 47.6ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 46.5ms\n","Speed: 1.8ms preprocess, 46.5ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 48.5ms\n","Speed: 1.8ms preprocess, 48.5ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 49.2ms\n","Speed: 1.8ms preprocess, 49.2ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 53.3ms\n","Speed: 1.7ms preprocess, 53.3ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 46.9ms\n","Speed: 1.7ms preprocess, 46.9ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 48.8ms\n","Speed: 1.6ms preprocess, 48.8ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 46.3ms\n","Speed: 1.8ms preprocess, 46.3ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 46.8ms\n","Speed: 1.6ms preprocess, 46.8ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 49.1ms\n","Speed: 2.3ms preprocess, 49.1ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 46.3ms\n","Speed: 1.7ms preprocess, 46.3ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 45.7ms\n","Speed: 1.7ms preprocess, 45.7ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 47.0ms\n","Speed: 1.8ms preprocess, 47.0ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 51.2ms\n","Speed: 2.1ms preprocess, 51.2ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 46.6ms\n","Speed: 1.6ms preprocess, 46.6ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 48.2ms\n","Speed: 1.7ms preprocess, 48.2ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 49.8ms\n","Speed: 1.7ms preprocess, 49.8ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 46.9ms\n","Speed: 1.6ms preprocess, 46.9ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 48.0ms\n","Speed: 1.7ms preprocess, 48.0ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 43.8ms\n","Speed: 1.7ms preprocess, 43.8ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 57.1ms\n","Speed: 1.7ms preprocess, 57.1ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 48.1ms\n","Speed: 1.7ms preprocess, 48.1ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 47.5ms\n","Speed: 1.7ms preprocess, 47.5ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 47.7ms\n","Speed: 1.5ms preprocess, 47.7ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 49.8ms\n","Speed: 1.5ms preprocess, 49.8ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 47.8ms\n","Speed: 1.5ms preprocess, 47.8ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 47.9ms\n","Speed: 1.6ms preprocess, 47.9ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 45.1ms\n","Speed: 1.5ms preprocess, 45.1ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 45.7ms\n","Speed: 1.5ms preprocess, 45.7ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 49.6ms\n","Speed: 1.5ms preprocess, 49.6ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 47.0ms\n","Speed: 1.4ms preprocess, 47.0ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 47.4ms\n","Speed: 1.5ms preprocess, 47.4ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 44.0ms\n","Speed: 1.7ms preprocess, 44.0ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 46.6ms\n","Speed: 1.5ms preprocess, 46.6ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 46.7ms\n","Speed: 1.6ms preprocess, 46.7ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 48.7ms\n","Speed: 1.5ms preprocess, 48.7ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 47.2ms\n","Speed: 1.7ms preprocess, 47.2ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 55.2ms\n","Speed: 1.8ms preprocess, 55.2ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 46.7ms\n","Speed: 1.7ms preprocess, 46.7ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 47.1ms\n","Speed: 1.5ms preprocess, 47.1ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 47.5ms\n","Speed: 2.0ms preprocess, 47.5ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 49.6ms\n","Speed: 1.4ms preprocess, 49.6ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 50.0ms\n","Speed: 1.7ms preprocess, 50.0ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 45.4ms\n","Speed: 1.5ms preprocess, 45.4ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 51.6ms\n","Speed: 1.5ms preprocess, 51.6ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 47.5ms\n","Speed: 1.5ms preprocess, 47.5ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 47.6ms\n","Speed: 1.6ms preprocess, 47.6ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 48.6ms\n","Speed: 1.5ms preprocess, 48.6ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 47.8ms\n","Speed: 1.6ms preprocess, 47.8ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 47.4ms\n","Speed: 1.5ms preprocess, 47.4ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 48.2ms\n","Speed: 1.5ms preprocess, 48.2ms inference, 0.8ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 47.4ms\n","Speed: 1.6ms preprocess, 47.4ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 50.3ms\n","Speed: 1.5ms preprocess, 50.3ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 52.8ms\n","Speed: 1.6ms preprocess, 52.8ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 47.6ms\n","Speed: 1.7ms preprocess, 47.6ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 46.5ms\n","Speed: 1.2ms preprocess, 46.5ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 46.7ms\n","Speed: 1.7ms preprocess, 46.7ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 53.9ms\n","Speed: 2.0ms preprocess, 53.9ms inference, 1.1ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 52.7ms\n","Speed: 1.6ms preprocess, 52.7ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 57.5ms\n","Speed: 2.3ms preprocess, 57.5ms inference, 1.1ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 53.1ms\n","Speed: 1.6ms preprocess, 53.1ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 48.6ms\n","Speed: 1.7ms preprocess, 48.6ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 49.3ms\n","Speed: 1.6ms preprocess, 49.3ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 47.9ms\n","Speed: 1.6ms preprocess, 47.9ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 51.2ms\n","Speed: 4.3ms preprocess, 51.2ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 46.9ms\n","Speed: 1.6ms preprocess, 46.9ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 49.1ms\n","Speed: 1.6ms preprocess, 49.1ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 48.5ms\n","Speed: 1.7ms preprocess, 48.5ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 46.2ms\n","Speed: 1.7ms preprocess, 46.2ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 58.3ms\n","Speed: 1.6ms preprocess, 58.3ms inference, 0.5ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 49.4ms\n","Speed: 1.6ms preprocess, 49.4ms inference, 0.5ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 46.8ms\n","Speed: 1.7ms preprocess, 46.8ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 46.3ms\n","Speed: 1.6ms preprocess, 46.3ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 48.1ms\n","Speed: 1.6ms preprocess, 48.1ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 46.5ms\n","Speed: 1.6ms preprocess, 46.5ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 46.5ms\n","Speed: 1.6ms preprocess, 46.5ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 51.8ms\n","Speed: 2.0ms preprocess, 51.8ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 48.8ms\n","Speed: 1.7ms preprocess, 48.8ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 48.2ms\n","Speed: 1.7ms preprocess, 48.2ms inference, 0.5ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 47.9ms\n","Speed: 1.5ms preprocess, 47.9ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 48.7ms\n","Speed: 1.8ms preprocess, 48.7ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 49.3ms\n","Speed: 2.5ms preprocess, 49.3ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 48.6ms\n","Speed: 1.8ms preprocess, 48.6ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 48.1ms\n","Speed: 1.9ms preprocess, 48.1ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 72.1ms\n","Speed: 1.9ms preprocess, 72.1ms inference, 0.5ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 85.8ms\n","Speed: 1.7ms preprocess, 85.8ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 49.6ms\n","Speed: 1.7ms preprocess, 49.6ms inference, 0.5ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 48.3ms\n","Speed: 3.7ms preprocess, 48.3ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 50.3ms\n","Speed: 1.6ms preprocess, 50.3ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 48.3ms\n","Speed: 1.9ms preprocess, 48.3ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 67.3ms\n","Speed: 1.8ms preprocess, 67.3ms inference, 0.5ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 77.6ms\n","Speed: 1.6ms preprocess, 77.6ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 76.8ms\n","Speed: 1.8ms preprocess, 76.8ms inference, 0.5ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 71.9ms\n","Speed: 1.6ms preprocess, 71.9ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 80.1ms\n","Speed: 1.8ms preprocess, 80.1ms inference, 0.5ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 72.3ms\n","Speed: 1.7ms preprocess, 72.3ms inference, 0.5ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 70.3ms\n","Speed: 1.7ms preprocess, 70.3ms inference, 0.5ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 75.9ms\n","Speed: 2.2ms preprocess, 75.9ms inference, 0.5ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 77.9ms\n","Speed: 1.9ms preprocess, 77.9ms inference, 0.5ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 73.8ms\n","Speed: 1.6ms preprocess, 73.8ms inference, 0.5ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 69.5ms\n","Speed: 2.1ms preprocess, 69.5ms inference, 0.5ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 68.9ms\n","Speed: 1.6ms preprocess, 68.9ms inference, 0.5ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 74.3ms\n","Speed: 1.7ms preprocess, 74.3ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 72.2ms\n","Speed: 2.3ms preprocess, 72.2ms inference, 0.5ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 71.3ms\n","Speed: 3.2ms preprocess, 71.3ms inference, 0.5ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 72.1ms\n","Speed: 1.6ms preprocess, 72.1ms inference, 0.5ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 69.4ms\n","Speed: 1.7ms preprocess, 69.4ms inference, 0.5ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 78.9ms\n","Speed: 1.6ms preprocess, 78.9ms inference, 0.5ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 92.7ms\n","Speed: 1.8ms preprocess, 92.7ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 79.9ms\n","Speed: 1.6ms preprocess, 79.9ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 76.7ms\n","Speed: 1.7ms preprocess, 76.7ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 74.9ms\n","Speed: 3.2ms preprocess, 74.9ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 74.6ms\n","Speed: 1.7ms preprocess, 74.6ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 79.6ms\n","Speed: 1.9ms preprocess, 79.6ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 76.2ms\n","Speed: 2.3ms preprocess, 76.2ms inference, 0.5ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 75.5ms\n","Speed: 2.1ms preprocess, 75.5ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 74.4ms\n","Speed: 1.6ms preprocess, 74.4ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 74.1ms\n","Speed: 1.5ms preprocess, 74.1ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 82.1ms\n","Speed: 1.7ms preprocess, 82.1ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 59.1ms\n","Speed: 1.7ms preprocess, 59.1ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 49.0ms\n","Speed: 1.6ms preprocess, 49.0ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 48.3ms\n","Speed: 2.1ms preprocess, 48.3ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 57.5ms\n","Speed: 1.6ms preprocess, 57.5ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 45.2ms\n","Speed: 2.0ms preprocess, 45.2ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 47.7ms\n","Speed: 1.7ms preprocess, 47.7ms inference, 0.8ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 48.4ms\n","Speed: 3.2ms preprocess, 48.4ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 49.0ms\n","Speed: 1.8ms preprocess, 49.0ms inference, 0.9ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 47.2ms\n","Speed: 1.8ms preprocess, 47.2ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 48.5ms\n","Speed: 1.6ms preprocess, 48.5ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 52.3ms\n","Speed: 2.4ms preprocess, 52.3ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 52.5ms\n","Speed: 1.7ms preprocess, 52.5ms inference, 0.8ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 54.8ms\n","Speed: 1.9ms preprocess, 54.8ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 48.9ms\n","Speed: 1.8ms preprocess, 48.9ms inference, 0.8ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 48.7ms\n","Speed: 1.8ms preprocess, 48.7ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 55.6ms\n","Speed: 1.6ms preprocess, 55.6ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 50.5ms\n","Speed: 1.6ms preprocess, 50.5ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 48.9ms\n","Speed: 1.6ms preprocess, 48.9ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 50.1ms\n","Speed: 1.5ms preprocess, 50.1ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 47.8ms\n","Speed: 1.9ms preprocess, 47.8ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 50.8ms\n","Speed: 1.6ms preprocess, 50.8ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 3 Mouses, 53.3ms\n","Speed: 1.6ms preprocess, 53.3ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 3 Mouses, 48.3ms\n","Speed: 1.8ms preprocess, 48.3ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 3 Mouses, 51.1ms\n","Speed: 1.6ms preprocess, 51.1ms inference, 0.9ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 48.5ms\n","Speed: 1.6ms preprocess, 48.5ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 48.5ms\n","Speed: 1.8ms preprocess, 48.5ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 47.6ms\n","Speed: 1.7ms preprocess, 47.6ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 47.7ms\n","Speed: 1.5ms preprocess, 47.7ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 46.5ms\n","Speed: 1.7ms preprocess, 46.5ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 48.1ms\n","Speed: 2.1ms preprocess, 48.1ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 47.3ms\n","Speed: 2.0ms preprocess, 47.3ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 56.2ms\n","Speed: 1.8ms preprocess, 56.2ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 3 Mouses, 53.0ms\n","Speed: 2.1ms preprocess, 53.0ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 47.8ms\n","Speed: 1.9ms preprocess, 47.8ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 47.6ms\n","Speed: 2.0ms preprocess, 47.6ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 44.0ms\n","Speed: 7.6ms preprocess, 44.0ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 3 Mouses, 46.8ms\n","Speed: 2.4ms preprocess, 46.8ms inference, 0.8ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 3 Mouses, 49.7ms\n","Speed: 1.6ms preprocess, 49.7ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 48.8ms\n","Speed: 1.7ms preprocess, 48.8ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 48.7ms\n","Speed: 1.8ms preprocess, 48.7ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 46.4ms\n","Speed: 1.9ms preprocess, 46.4ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 49.0ms\n","Speed: 1.8ms preprocess, 49.0ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 46.3ms\n","Speed: 1.6ms preprocess, 46.3ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 49.9ms\n","Speed: 1.7ms preprocess, 49.9ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 3 Mouses, 50.4ms\n","Speed: 1.7ms preprocess, 50.4ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 50.6ms\n","Speed: 1.5ms preprocess, 50.6ms inference, 0.9ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 47.0ms\n","Speed: 1.5ms preprocess, 47.0ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 57.0ms\n","Speed: 1.7ms preprocess, 57.0ms inference, 1.1ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 48.3ms\n","Speed: 1.7ms preprocess, 48.3ms inference, 0.8ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 46.8ms\n","Speed: 1.6ms preprocess, 46.8ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 50.6ms\n","Speed: 1.8ms preprocess, 50.6ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 48.2ms\n","Speed: 1.6ms preprocess, 48.2ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 47.9ms\n","Speed: 1.6ms preprocess, 47.9ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 47.7ms\n","Speed: 1.7ms preprocess, 47.7ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 47.0ms\n","Speed: 1.6ms preprocess, 47.0ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 47.7ms\n","Speed: 1.7ms preprocess, 47.7ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 3 Mouses, 49.5ms\n","Speed: 1.6ms preprocess, 49.5ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 48.4ms\n","Speed: 1.7ms preprocess, 48.4ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 45.1ms\n","Speed: 1.2ms preprocess, 45.1ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 47.7ms\n","Speed: 1.7ms preprocess, 47.7ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 48.9ms\n","Speed: 1.8ms preprocess, 48.9ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 47.4ms\n","Speed: 1.5ms preprocess, 47.4ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 49.6ms\n","Speed: 1.5ms preprocess, 49.6ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 49.4ms\n","Speed: 1.5ms preprocess, 49.4ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 54.1ms\n","Speed: 1.5ms preprocess, 54.1ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 48.8ms\n","Speed: 1.7ms preprocess, 48.8ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 48.9ms\n","Speed: 1.6ms preprocess, 48.9ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 46.3ms\n","Speed: 2.7ms preprocess, 46.3ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 65.7ms\n","Speed: 1.9ms preprocess, 65.7ms inference, 0.8ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 56.7ms\n","Speed: 3.0ms preprocess, 56.7ms inference, 0.8ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 50.0ms\n","Speed: 2.5ms preprocess, 50.0ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 46.6ms\n","Speed: 2.8ms preprocess, 46.6ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 44.1ms\n","Speed: 4.2ms preprocess, 44.1ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 45.0ms\n","Speed: 2.5ms preprocess, 45.0ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 48.7ms\n","Speed: 1.6ms preprocess, 48.7ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 49.3ms\n","Speed: 1.6ms preprocess, 49.3ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 44.8ms\n","Speed: 1.6ms preprocess, 44.8ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 52.2ms\n","Speed: 1.6ms preprocess, 52.2ms inference, 0.8ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 48.4ms\n","Speed: 1.9ms preprocess, 48.4ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 54.0ms\n","Speed: 1.7ms preprocess, 54.0ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 51.7ms\n","Speed: 1.7ms preprocess, 51.7ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 47.3ms\n","Speed: 1.7ms preprocess, 47.3ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 48.7ms\n","Speed: 1.3ms preprocess, 48.7ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 71.2ms\n","Speed: 1.7ms preprocess, 71.2ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 49.5ms\n","Speed: 1.6ms preprocess, 49.5ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 48.0ms\n","Speed: 1.4ms preprocess, 48.0ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 49.0ms\n","Speed: 1.7ms preprocess, 49.0ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 49.3ms\n","Speed: 1.6ms preprocess, 49.3ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 45.0ms\n","Speed: 1.5ms preprocess, 45.0ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 56.7ms\n","Speed: 1.6ms preprocess, 56.7ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 49.0ms\n","Speed: 1.5ms preprocess, 49.0ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 46.4ms\n","Speed: 1.4ms preprocess, 46.4ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 3 Mouses, 46.3ms\n","Speed: 1.7ms preprocess, 46.3ms inference, 0.8ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 48.1ms\n","Speed: 1.5ms preprocess, 48.1ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 45.4ms\n","Speed: 1.2ms preprocess, 45.4ms inference, 0.8ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 58.2ms\n","Speed: 1.7ms preprocess, 58.2ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 47.4ms\n","Speed: 1.6ms preprocess, 47.4ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 46.5ms\n","Speed: 1.6ms preprocess, 46.5ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 48.5ms\n","Speed: 1.7ms preprocess, 48.5ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 49.2ms\n","Speed: 1.6ms preprocess, 49.2ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 47.0ms\n","Speed: 1.5ms preprocess, 47.0ms inference, 0.8ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 52.8ms\n","Speed: 1.5ms preprocess, 52.8ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 49.8ms\n","Speed: 1.5ms preprocess, 49.8ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 47.3ms\n","Speed: 2.2ms preprocess, 47.3ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 48.9ms\n","Speed: 1.6ms preprocess, 48.9ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 45.4ms\n","Speed: 1.7ms preprocess, 45.4ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 4 Mouses, 46.3ms\n","Speed: 1.6ms preprocess, 46.3ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 4 Mouses, 48.3ms\n","Speed: 1.6ms preprocess, 48.3ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 3 Mouses, 48.7ms\n","Speed: 1.6ms preprocess, 48.7ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 3 Mouses, 49.2ms\n","Speed: 1.6ms preprocess, 49.2ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 48.4ms\n","Speed: 1.6ms preprocess, 48.4ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 3 Mouses, 62.7ms\n","Speed: 1.7ms preprocess, 62.7ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 45.8ms\n","Speed: 1.6ms preprocess, 45.8ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 49.1ms\n","Speed: 1.6ms preprocess, 49.1ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 52.7ms\n","Speed: 1.7ms preprocess, 52.7ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 48.3ms\n","Speed: 1.7ms preprocess, 48.3ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 48.3ms\n","Speed: 1.5ms preprocess, 48.3ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 50.7ms\n","Speed: 1.6ms preprocess, 50.7ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 46.0ms\n","Speed: 1.7ms preprocess, 46.0ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 47.0ms\n","Speed: 1.7ms preprocess, 47.0ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 50.3ms\n","Speed: 1.6ms preprocess, 50.3ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 49.9ms\n","Speed: 1.6ms preprocess, 49.9ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 49.4ms\n","Speed: 2.2ms preprocess, 49.4ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 51.1ms\n","Speed: 1.5ms preprocess, 51.1ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 53.6ms\n","Speed: 1.7ms preprocess, 53.6ms inference, 0.5ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 49.5ms\n","Speed: 1.5ms preprocess, 49.5ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 51.0ms\n","Speed: 1.6ms preprocess, 51.0ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 60.7ms\n","Speed: 1.7ms preprocess, 60.7ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 49.4ms\n","Speed: 1.6ms preprocess, 49.4ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 50.6ms\n","Speed: 1.6ms preprocess, 50.6ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 50.2ms\n","Speed: 2.2ms preprocess, 50.2ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 49.7ms\n","Speed: 2.1ms preprocess, 49.7ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 50.1ms\n","Speed: 2.1ms preprocess, 50.1ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 3 Mouses, 50.5ms\n","Speed: 2.1ms preprocess, 50.5ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 48.7ms\n","Speed: 1.8ms preprocess, 48.7ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 49.8ms\n","Speed: 1.7ms preprocess, 49.8ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 3 Mouses, 49.4ms\n","Speed: 2.1ms preprocess, 49.4ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 3 Mouses, 49.5ms\n","Speed: 1.6ms preprocess, 49.5ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 3 Mouses, 46.7ms\n","Speed: 2.0ms preprocess, 46.7ms inference, 0.8ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 52.2ms\n","Speed: 1.8ms preprocess, 52.2ms inference, 0.8ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 47.4ms\n","Speed: 1.7ms preprocess, 47.4ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 48.8ms\n","Speed: 1.6ms preprocess, 48.8ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 52.8ms\n","Speed: 2.0ms preprocess, 52.8ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 51.5ms\n","Speed: 1.7ms preprocess, 51.5ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 48.7ms\n","Speed: 1.9ms preprocess, 48.7ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 51.3ms\n","Speed: 1.8ms preprocess, 51.3ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 49.8ms\n","Speed: 1.5ms preprocess, 49.8ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 49.2ms\n","Speed: 1.5ms preprocess, 49.2ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 49.6ms\n","Speed: 1.8ms preprocess, 49.6ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 47.6ms\n","Speed: 1.9ms preprocess, 47.6ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 46.9ms\n","Speed: 3.8ms preprocess, 46.9ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 49.1ms\n","Speed: 1.7ms preprocess, 49.1ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 4 Mouses, 49.9ms\n","Speed: 1.6ms preprocess, 49.9ms inference, 4.4ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 63.0ms\n","Speed: 2.0ms preprocess, 63.0ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 73.7ms\n","Speed: 2.0ms preprocess, 73.7ms inference, 1.1ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 76.9ms\n","Speed: 1.6ms preprocess, 76.9ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 82.7ms\n","Speed: 5.4ms preprocess, 82.7ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 85.1ms\n","Speed: 1.7ms preprocess, 85.1ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 78.6ms\n","Speed: 2.0ms preprocess, 78.6ms inference, 3.0ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 72.0ms\n","Speed: 3.0ms preprocess, 72.0ms inference, 4.2ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 70.3ms\n","Speed: 1.8ms preprocess, 70.3ms inference, 0.9ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 69.9ms\n","Speed: 1.7ms preprocess, 69.9ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 75.0ms\n","Speed: 1.7ms preprocess, 75.0ms inference, 0.9ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 72.5ms\n","Speed: 1.7ms preprocess, 72.5ms inference, 0.8ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 80.4ms\n","Speed: 1.7ms preprocess, 80.4ms inference, 0.8ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 70.3ms\n","Speed: 1.7ms preprocess, 70.3ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 70.7ms\n","Speed: 4.5ms preprocess, 70.7ms inference, 0.8ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 73.7ms\n","Speed: 1.7ms preprocess, 73.7ms inference, 0.8ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 72.7ms\n","Speed: 1.6ms preprocess, 72.7ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 79.0ms\n","Speed: 1.7ms preprocess, 79.0ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 77.6ms\n","Speed: 3.8ms preprocess, 77.6ms inference, 3.0ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 77.1ms\n","Speed: 1.7ms preprocess, 77.1ms inference, 0.9ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 72.7ms\n","Speed: 1.5ms preprocess, 72.7ms inference, 0.9ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 77.0ms\n","Speed: 1.7ms preprocess, 77.0ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 74.5ms\n","Speed: 1.6ms preprocess, 74.5ms inference, 0.9ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 70.4ms\n","Speed: 1.7ms preprocess, 70.4ms inference, 0.9ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 71.8ms\n","Speed: 1.8ms preprocess, 71.8ms inference, 1.1ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 2 Mouses, 85.3ms\n","Speed: 2.2ms preprocess, 85.3ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 77.3ms\n","Speed: 1.6ms preprocess, 77.3ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 74.6ms\n","Speed: 2.7ms preprocess, 74.6ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 50.3ms\n","Speed: 1.6ms preprocess, 50.3ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 44.2ms\n","Speed: 1.7ms preprocess, 44.2ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 1 Mouse, 45.8ms\n","Speed: 1.7ms preprocess, 45.8ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 47.1ms\n","Speed: 6.1ms preprocess, 47.1ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 45.9ms\n","Speed: 1.5ms preprocess, 45.9ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 50.5ms\n","Speed: 1.7ms preprocess, 50.5ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 49.3ms\n","Speed: 2.0ms preprocess, 49.3ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 416)\n","\n","0: 256x416 (no detections), 45.8ms\n","Speed: 1.6ms preprocess, 45.8ms inference, 0.5ms postprocess per image at shape (1, 3, 256, 416)\n","Total processing time: 25.90 seconds\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_acc7d532-8a73-40aa-8ba9-b44e077c5951\", \"output_video.mp4\", 4781422)"]},"metadata":{}}]},{"cell_type":"code","source":["\n","\n","# Compress the folder\n","!zip -r sample_folder.zip /content/FYP/runs/detect/custom_yolo11n\n","\n","# Download the ZIP file\n","from google.colab import files\n","files.download('sample_folder.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":503},"id":"s_AVercopbu3","executionInfo":{"status":"ok","timestamp":1744388416852,"user_tz":-480,"elapsed":812,"user":{"displayName":"Sit Chun Yin","userId":"16986499505322810919"}},"outputId":"4a656177-af31-4f84-bfb7-82c6b7eb281a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: content/FYP/runs/detect/custom_yolo11n/ (stored 0%)\n","  adding: content/FYP/runs/detect/custom_yolo11n/val_batch2_pred.jpg (deflated 14%)\n","  adding: content/FYP/runs/detect/custom_yolo11n/train_batch2.jpg (deflated 10%)\n","  adding: content/FYP/runs/detect/custom_yolo11n/train_batch9211.jpg (deflated 17%)\n","  adding: content/FYP/runs/detect/custom_yolo11n/confusion_matrix_normalized.png (deflated 34%)\n","  adding: content/FYP/runs/detect/custom_yolo11n/args.yaml (deflated 53%)\n","  adding: content/FYP/runs/detect/custom_yolo11n/confusion_matrix.png (deflated 37%)\n","  adding: content/FYP/runs/detect/custom_yolo11n/labels.jpg (deflated 35%)\n","  adding: content/FYP/runs/detect/custom_yolo11n/weights/ (stored 0%)\n","  adding: content/FYP/runs/detect/custom_yolo11n/weights/best.pt (deflated 11%)\n","  adding: content/FYP/runs/detect/custom_yolo11n/weights/last.pt (deflated 11%)\n","  adding: content/FYP/runs/detect/custom_yolo11n/F1_curve.png (deflated 10%)\n","  adding: content/FYP/runs/detect/custom_yolo11n/R_curve.png (deflated 14%)\n","  adding: content/FYP/runs/detect/custom_yolo11n/val_batch0_pred.jpg (deflated 17%)\n","  adding: content/FYP/runs/detect/custom_yolo11n/val_batch0_labels.jpg (deflated 18%)\n","  adding: content/FYP/runs/detect/custom_yolo11n/results.png (deflated 8%)\n","  adding: content/FYP/runs/detect/custom_yolo11n/val_batch1_labels.jpg (deflated 11%)\n","  adding: content/FYP/runs/detect/custom_yolo11n/train_batch9212.jpg (deflated 16%)\n","  adding: content/FYP/runs/detect/custom_yolo11n/labels_correlogram.jpg (deflated 41%)\n","  adding: content/FYP/runs/detect/custom_yolo11n/P_curve.png (deflated 11%)\n","  adding: content/FYP/runs/detect/custom_yolo11n/train_batch9210.jpg (deflated 23%)\n","  adding: content/FYP/runs/detect/custom_yolo11n/val_batch1_pred.jpg (deflated 11%)\n","  adding: content/FYP/runs/detect/custom_yolo11n/PR_curve.png (deflated 19%)\n","  adding: content/FYP/runs/detect/custom_yolo11n/train_batch0.jpg (deflated 9%)\n","  adding: content/FYP/runs/detect/custom_yolo11n/train_batch1.jpg (deflated 8%)\n","  adding: content/FYP/runs/detect/custom_yolo11n/events.out.tfevents.1744386006.8ddbf72acf8d.2013.0 (deflated 91%)\n","  adding: content/FYP/runs/detect/custom_yolo11n/val_batch2_labels.jpg (deflated 15%)\n","  adding: content/FYP/runs/detect/custom_yolo11n/results.csv (deflated 60%)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_df351c97-8044-497c-8cc0-4f45b312e9f5\", \"sample_folder.zip\", 13357589)"]},"metadata":{}}]}]}